import fs from "node:fs/promises";
import path from "node:path";
import { fileURLToPath } from "node:url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// scripts/.. => repo root
const rootDir = path.resolve(__dirname, "..");
const outDir = path.join(rootDir, "src", "generated");

const presets = [
  { name: "small", bytes: 1_000_000 },
  { name: "medium", bytes: 5_000_000 },
  { name: "large", bytes: 15_000_000 },
];

const overrideBytes = process.env.HUGE_BYTES
  ? Number.parseInt(process.env.HUGE_BYTES, 10)
  : undefined;

if (
  overrideBytes !== undefined &&
  (!Number.isFinite(overrideBytes) || overrideBytes <= 0)
) {
  throw new Error(`Invalid HUGE_BYTES: ${process.env.HUGE_BYTES}`);
}

const alphabet =
  "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_";
const lineLen = 200;

await fs.mkdir(outDir, { recursive: true });

const targets = overrideBytes
  ? [{ name: "custom", bytes: overrideBytes }]
  : presets;

for (const target of targets) {
  let remaining = target.bytes;
  const lines = [];

  while (remaining > 0) {
    const take = Math.min(remaining, lineLen);
    const line = alphabet.repeat(Math.ceil(take / alphabet.length)).slice(
      0,
      take,
    );
    lines.push(line);
    remaining -= take;
  }

  const payload = lines.join("\n");
  const outFile = path.join(outDir, `huge-data-${target.name}.ts`);
  const contents = `/* AUTO-GENERATED by scripts/generate-huge-module.mjs
 * This file intentionally bloats the client bundle for testing.
 * Regenerate with: HUGE_BYTES=20000000 npm run generate:huge
 */
export const hugeData = ${JSON.stringify(payload)} as const;
export const hugeDataBytes = hugeData.length;
`;

  await fs.writeFile(outFile, contents, "utf8");
  console.log(`Wrote ${outFile} (~${payload.length} chars payload)`);
}
